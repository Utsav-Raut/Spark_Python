{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9161d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579be2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName('RDD_Actions').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25110db4",
   "metadata": {},
   "source": [
    "# Creating an RDD using parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e95f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Z',1),('A',20),('B',30),('C',40),('B',30),('B',60)]\n",
    "inputRdd = spark.sparkContext.parallelize(data, 10)\n",
    "\n",
    "listRdd = spark.sparkContext.parallelize([1,2,3,4,5,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447b955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Z', 1)\n",
      "('A', 20)\n",
      "('B', 30)\n",
      "('C', 40)\n",
      "('B', 30)\n",
      "('B', 60)\n"
     ]
    }
   ],
   "source": [
    "input_collect = inputRdd.collect()\n",
    "for i in input_collect:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad0a578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "list_collect = listRdd.collect()\n",
    "for i in list_collect:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4528dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(inputRdd.getNumPartitions())\n",
    "print(listRdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91aee3",
   "metadata": {},
   "source": [
    "# # Creating an RDD from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45d9c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "txt_file_RDD = spark.sparkContext.textFile('file:///home/boom/Desktop/hadoop.txt', 4)\n",
    "print(txt_file_RDD.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11e19497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created a example1.txt file with some sentences.\n",
      "\n",
      "created a hdfs user directory using:\n",
      "hdfs dfs -mkdir /user\n",
      "hdfs dfs -mkdir /user/boom\n",
      "hdfs dfs -mkdir /user/boom/practice_data\n",
      "\n",
      "hdfs dfs -put ./path_to_txt_file /user/boom/practice_data\n",
      "\n",
      "\n",
      "to see the file:\n",
      "cat /user/boom/practice_data/example1.txt\n",
      "\n",
      "\n",
      "To perform mapreduce:\n",
      "\n",
      "hadoop jar /home/boom/Documents/Programming/big_data/hadoop-3.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar wordcount /user/boom/practice_data/example1.txt /user/boom/firstExampleOut\n",
      "\n",
      "\n",
      "hadoop jar hadoop-mapreduce-examples-3.2.0.jar wordcount /user/boom/practice_data/example1.txt /user/boom/firstExampleOut\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt_col = txt_file_RDD.collect()\n",
    "for x in txt_col:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a349e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "txt_file_RDD = txt_file_RDD.repartition(6)\n",
    "print(txt_file_RDD.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e29dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
