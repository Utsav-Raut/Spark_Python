{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85dbbbff",
   "metadata": {},
   "source": [
    "# Dataframes:\n",
    "\n",
    "The concept of dataframe comes from the world of statistical tools/softwares used in emperical research. \n",
    "Dataframes are designed for processing large quantities of structured and semi-structured data. Observation in spark dataframe are organized under named columns which helps apache spark to understand the schema of a dataframe. This helps Spark optimize execution plan on these queries.\n",
    "Dataframes in Apache Spark has the ability to handle petabytes of data. It is usually used for handling the Big Data. \n",
    "It has support for wide range of data formats and sources.\n",
    "It has API support for different languages like Python, R, Java, Scala which makes it easier for people having different programming background as well.\n",
    "\n",
    "Dataframe APIs support elaborate methods for slicing and dicing the data.\n",
    "It includes operations such as selecting rows, columns and cell by name, or by number filtering out rows and many other operations.\n",
    "Another critically important feature of a dataframe is the explicit management of missing data.\n",
    "\n",
    "Dataframes refers to tabular data - a data structure representing rows, each of which consists of a number of observations or measurements which are known as columns. Alternatively each row may be treated as a single observation of multiple variables.\n",
    "Dataframes also contain some metadata in addition to the data, for example the column and the row names.\n",
    "Dataframe is like a 2D data-structure similar to a SQL or a table in a spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d118d1e",
   "metadata": {},
   "source": [
    "# Features of DataFrame:\n",
    "Firstly, they are \"distributed\" in nature which makes them highy available and fault tolerant.\n",
    "Secondly they support lazy evaluations, which increases manageability, speed, computation, provides optimization by reducing the number of queries, decreases complexities.\n",
    "Thirdly it is immutable, i.e an object whose state cannot be modified after it has been created. But we can transform its values by performing some transformations like in RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f036f4",
   "metadata": {},
   "source": [
    "# Creating DataFrames\n",
    "A dataframe in Spark can be created in mutiple ways.\n",
    "It can be created using different data formats for example loading data from json, csv, xml, parquet files. It can also be created from an existing RDD as well as from various dbs like Hive db, Cassandra db. Also we can create Dataframes from files residing in file systems as well as HDFS."
   ]
  },
  {
   "cell_type": "raw",
   "id": "902931c3",
   "metadata": {},
   "source": [
    "pyspark.sql.SQLContext is the main entry point for a dataframe and sql functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa110a",
   "metadata": {},
   "source": [
    "<h2>Important Classes</h2>\n",
    "<ul>\n",
    "<li>pyspark.sql.SQLContext</li>\n",
    "<li>pyspark.sql.DataFrame</li>\n",
    "<li>pyspark.sql.Column</li>\n",
    "<li>pyspark.sql.Row</li>\n",
    "<li>pyspark.sql.GroupedData</li>\n",
    "<li>pyspark.sql.DataFrameNAFunctions</li>\n",
    "<li>pyspark.sql.DataFrameStatFunctions</li>\n",
    "<li>pyspark.sql.functions</li>\n",
    "<li>pyspark.sql.types</li>\n",
    "<li>pyspark.sql.Window</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc27a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49eb9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"DataFrames1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dbdf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607386f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee1 = employee(\"Bruce\", \"Wayne\", \"BruceWayne@waynecorp.org\", 152666)\n",
    "employee2 = employee(\"Clark\", \"Kent\", \"ClarKent@oscorp.org\", 79985)\n",
    "employee3 = employee(\"Diana\", \"Prince\", \"DianaPrince@themyscire.org\", 58874)\n",
    "employee4 = employee(\"Barry\", \"Allen\", \"BarryAllen@wstarlabs.org\", 233541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51ddd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "department1 = Row(id='123456', name='HR')\n",
    "department2 = Row(id='789012', name='OPS')\n",
    "department3 = Row(id='345678', name='FN')\n",
    "department4 = Row(id='901234', name='DEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da6c5621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(firstName='Diana', lastName='Prince', email='DianaPrince@themyscire.org', salary=58874)\n"
     ]
    }
   ],
   "source": [
    "print(employee3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1065a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstName\n"
     ]
    }
   ],
   "source": [
    "print(employee[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b4f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\n",
    "departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\n",
    "departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4, employee3])\n",
    "departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb1d050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='901234', name='DEV')\n"
     ]
    }
   ],
   "source": [
    "print(department4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60fd90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "departmentsWithEmployees_Seq = [departmentWithEmployees1, departmentWithEmployees2]\n",
    "dframe = spark.createDataFrame(departmentsWithEmployees_Seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ab21a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[department: struct<id:string,name:string>, employees: array<struct<firstName:string,lastName:string,email:string,salary:bigint>>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ddda56",
   "metadata": {},
   "source": [
    "# Creating DataFrame using an actual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49191995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default the \"read\" method will look for a file in HDFS, so we need to specify the filnename\n",
    "# as \"file:///\"\n",
    "\n",
    "fifa_df = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(\"file:///home/boom/Documents/programming/pyspark/data_files/my_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6006290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+--------------------+--------------------+--------------+\n",
      "| id|firstname| lastname|               email|              email2|    profession|\n",
      "+---+---------+---------+--------------------+--------------------+--------------+\n",
      "|100|    Lynde|   Orelee|Lynde.Orelee@yopm...|Lynde.Orelee@gmai...|   firefighter|\n",
      "|101|     Vere|  Charity|Vere.Charity@yopm...|Vere.Charity@gmai...|police officer|\n",
      "|102|    Verla| Demitria|Verla.Demitria@yo...|Verla.Demitria@gm...|        worker|\n",
      "|103|   Ebonee|     Etom|Ebonee.Etom@yopma...|Ebonee.Etom@gmail...|     developer|\n",
      "|104|   Orsola|  Fadiman|Orsola.Fadiman@yo...|Orsola.Fadiman@gm...|        doctor|\n",
      "|105|   Ofilia| Eliathas|Ofilia.Eliathas@y...|Ofilia.Eliathas@g...|police officer|\n",
      "|106| Willetta|     Ajay|Willetta.Ajay@yop...|Willetta.Ajay@gma...|     developer|\n",
      "|107|Ekaterina|       An|Ekaterina.An@yopm...|Ekaterina.An@gmai...|     developer|\n",
      "|108|  Gusella|  Emanuel|Gusella.Emanuel@y...|Gusella.Emanuel@g...|police officer|\n",
      "|109|    Robbi|  Jaylene|Robbi.Jaylene@yop...|Robbi.Jaylene@gma...|        worker|\n",
      "|110|   Melina|  Gusella|Melina.Gusella@yo...|Melina.Gusella@gm...|     developer|\n",
      "|111|   Leanna|    Garbe|Leanna.Garbe@yopm...|Leanna.Garbe@gmai...|        worker|\n",
      "|112|    Grier|  Fabiola|Grier.Fabiola@yop...|Grier.Fabiola@gma...|   firefighter|\n",
      "|113|    Linzy|       An|Linzy.An@yopmail.com|  Linzy.An@gmail.com|        worker|\n",
      "|114|     Fina| Sidonius|Fina.Sidonius@yop...|Fina.Sidonius@gma...|        doctor|\n",
      "|115|  Brianna|   Drisko|Brianna.Drisko@yo...|Brianna.Drisko@gm...|        worker|\n",
      "|116|Morganica| Kendrick|Morganica.Kendric...|Morganica.Kendric...|     developer|\n",
      "|117|  Chloris| Pulsifer|Chloris.Pulsifer@...|Chloris.Pulsifer@...|        doctor|\n",
      "|118|  Aeriela|Erlandson|Aeriela.Erlandson...|Aeriela.Erlandson...|        worker|\n",
      "|119|   Dennie|    Trace|Dennie.Trace@yopm...|Dennie.Trace@gmai...|     developer|\n",
      "+---+---------+---------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6584d116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- email2: string (nullable = true)\n",
      " |-- profession: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe90d1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'firstname', 'lastname', 'email', 'email2', 'profession']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96b60c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b49597cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fifa_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "155c41ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|               id|\n",
      "+-------+-----------------+\n",
      "|  count|             1000|\n",
      "|   mean|            599.5|\n",
      "| stddev|288.8194360957494|\n",
      "|    min|              100|\n",
      "|    max|             1099|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.describe('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10a54828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|lastname|\n",
      "+-------+--------+\n",
      "|  count|    1000|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|   Abbot|\n",
      "|    max|  Zuzana|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.describe('lastname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa55e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_df.describe('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0947d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee272864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|firstname| lastname|\n",
      "+---------+---------+\n",
      "|    Lynde|   Orelee|\n",
      "|     Vere|  Charity|\n",
      "|    Verla| Demitria|\n",
      "|   Ebonee|     Etom|\n",
      "|   Orsola|  Fadiman|\n",
      "|   Ofilia| Eliathas|\n",
      "| Willetta|     Ajay|\n",
      "|Ekaterina|       An|\n",
      "|  Gusella|  Emanuel|\n",
      "|    Robbi|  Jaylene|\n",
      "|   Melina|  Gusella|\n",
      "|   Leanna|    Garbe|\n",
      "|    Grier|  Fabiola|\n",
      "|    Linzy|       An|\n",
      "|     Fina| Sidonius|\n",
      "|  Brianna|   Drisko|\n",
      "|Morganica| Kendrick|\n",
      "|  Chloris| Pulsifer|\n",
      "|  Aeriela|Erlandson|\n",
      "|   Dennie|    Trace|\n",
      "+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.select(\"firstname\", \"lastname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_df.filter(fifa_df.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
