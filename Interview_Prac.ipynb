{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bcb600",
   "metadata": {},
   "source": [
    "# RDD stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2fcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c77ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fdd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName('Interview_Prep').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df5d36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 1)\n",
      "('B', 2)\n",
      "('C', 3)\n"
     ]
    }
   ],
   "source": [
    "list1 = [('A', 1), ('B', 2), ('C', 3)]\n",
    "df1 = spark.sparkContext.parallelize(list1)\n",
    "collected_df = df1.collect()\n",
    "for data in collected_df:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34fc4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9eeed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('file:/home/boom/Desktop/hadoop.txt', 'created a example1.txt file with some sentences.\\n\\ncreated a hdfs user directory using:\\nhdfs dfs -mkdir /user\\nhdfs dfs -mkdir /user/boom\\nhdfs dfs -mkdir /user/boom/practice_data\\n\\nhdfs dfs -put ./path_to_txt_file /user/boom/practice_data\\n\\n\\nto see the file:\\ncat /user/boom/practice_data/example1.txt\\n\\n\\nTo perform mapreduce:\\n\\nhadoop jar /home/boom/Documents/Programming/big_data/hadoop-3.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar wordcount /user/boom/practice_data/example1.txt /user/boom/firstExampleOut\\n\\n\\nhadoop jar hadoop-mapreduce-examples-3.2.0.jar wordcount /user/boom/practice_data/example1.txt /user/boom/firstExampleOut\\n\\n\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.sparkContext.wholeTextFiles('file:///home/boom/Desktop/hadoop.txt')\n",
    "collected_df2 = df2.collect()\n",
    "for y in collected_df2:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27de00b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created a example1.txt file with some sentences.\n",
      "\n",
      "created a hdfs user directory using:\n",
      "hdfs dfs -mkdir /user\n",
      "hdfs dfs -mkdir /user/boom\n",
      "hdfs dfs -mkdir /user/boom/practice_data\n",
      "\n",
      "hdfs dfs -put ./path_to_txt_file /user/boom/practice_data\n",
      "\n",
      "\n",
      "to see the file:\n",
      "cat /user/boom/practice_data/example1.txt\n",
      "\n",
      "\n",
      "To perform mapreduce:\n",
      "\n",
      "hadoop jar /home/boom/Documents/Programming/big_data/hadoop-3.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.0.jar wordcount /user/boom/practice_data/example1.txt /user/boom/firstExampleOut\n",
      "\n",
      "\n",
      "hadoop jar hadoop-mapreduce-examples-3.2.0.jar wordcount /user/boom/practice_data/example1.txt /user/boom/firstExampleOut\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.sparkContext.textFile('file:///home/boom/Desktop/hadoop.txt')\n",
    "collected_df3 = df3.collect()\n",
    "for z in collected_df3:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e623ac",
   "metadata": {},
   "source": [
    "# Dataframe stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6faebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = Row(\"id\", \"firstname\", \"lastname\", \"gender\", \"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7734d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------+------+\n",
      "| id|firstname|lastname|gender|salary|\n",
      "+---+---------+--------+------+------+\n",
      "|102|    Bruce|   Wayne|     M| 95000|\n",
      "|106|    Clark|    Kent|     M| 77000|\n",
      "|101|    Diana|  Prince|     F| 90000|\n",
      "|111|     Lois|    Lane|     F|145000|\n",
      "+---+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee1 = Row(102, \"Bruce\", \"Wayne\", \"M\", 95000)\n",
    "employee2 = Row(106, \"Clark\", \"Kent\", \"M\", 77000)\n",
    "employee3 = Row(101, \"Diana\", \"Prince\", \"F\", 90000)\n",
    "employee4 = Row(111, \"Lois\", \"Lane\", \"F\", 145000)\n",
    "list_of_employees = [employee1, employee2, employee3, employee4]\n",
    "emp_df = spark.createDataFrame(data=list_of_employees, schema=employee)\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5daaf",
   "metadata": {},
   "source": [
    "<p>Creating dataframes with file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f878364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+--------------------+--------------------+--------------+\n",
      "| id|firstname| lastname|               email|              email2|    profession|\n",
      "+---+---------+---------+--------------------+--------------------+--------------+\n",
      "|100|    Lynde|   Orelee|Lynde.Orelee@yopm...|Lynde.Orelee@gmai...|   firefighter|\n",
      "|101|     Vere|  Charity|Vere.Charity@yopm...|Vere.Charity@gmai...|police officer|\n",
      "|102|    Verla| Demitria|Verla.Demitria@yo...|Verla.Demitria@gm...|        worker|\n",
      "|103|   Ebonee|     Etom|Ebonee.Etom@yopma...|Ebonee.Etom@gmail...|     developer|\n",
      "|104|   Orsola|  Fadiman|Orsola.Fadiman@yo...|Orsola.Fadiman@gm...|        doctor|\n",
      "|105|   Ofilia| Eliathas|Ofilia.Eliathas@y...|Ofilia.Eliathas@g...|police officer|\n",
      "|106| Willetta|     Ajay|Willetta.Ajay@yop...|Willetta.Ajay@gma...|     developer|\n",
      "|107|Ekaterina|       An|Ekaterina.An@yopm...|Ekaterina.An@gmai...|     developer|\n",
      "|108|  Gusella|  Emanuel|Gusella.Emanuel@y...|Gusella.Emanuel@g...|police officer|\n",
      "|109|    Robbi|  Jaylene|Robbi.Jaylene@yop...|Robbi.Jaylene@gma...|        worker|\n",
      "|110|   Melina|  Gusella|Melina.Gusella@yo...|Melina.Gusella@gm...|     developer|\n",
      "|111|   Leanna|    Garbe|Leanna.Garbe@yopm...|Leanna.Garbe@gmai...|        worker|\n",
      "|112|    Grier|  Fabiola|Grier.Fabiola@yop...|Grier.Fabiola@gma...|   firefighter|\n",
      "|113|    Linzy|       An|Linzy.An@yopmail.com|  Linzy.An@gmail.com|        worker|\n",
      "|114|     Fina| Sidonius|Fina.Sidonius@yop...|Fina.Sidonius@gma...|        doctor|\n",
      "|115|  Brianna|   Drisko|Brianna.Drisko@yo...|Brianna.Drisko@gm...|        worker|\n",
      "|116|Morganica| Kendrick|Morganica.Kendric...|Morganica.Kendric...|     developer|\n",
      "|117|  Chloris| Pulsifer|Chloris.Pulsifer@...|Chloris.Pulsifer@...|        doctor|\n",
      "|118|  Aeriela|Erlandson|Aeriela.Erlandson...|Aeriela.Erlandson...|        worker|\n",
      "|119|   Dennie|    Trace|Dennie.Trace@yopm...|Dennie.Trace@gmai...|     developer|\n",
      "+---+---------+---------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df = spark.read.format('csv').option(\"inferSchema\", True).option(\"header\", True).load(\"file:///home/boom/Documents/programming/pyspark/data_files/my_data.csv\")\n",
    "fifa_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4d1573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- email2: string (nullable = true)\n",
      " |-- profession: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d56557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'firstname', 'lastname', 'email', 'email2', 'profession']\n",
      "6\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(fifa_df.columns)\n",
    "print(len(fifa_df.columns))\n",
    "print(fifa_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02434754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|lastname|\n",
      "+-------+--------+\n",
      "|  count|    1000|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|   Abbot|\n",
      "|    max|  Zuzana|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.describe('lastname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c14c3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------+------+\n",
      "| id|firstname|lastname|gender|salary|\n",
      "+---+---------+--------+------+------+\n",
      "|106|    Clark|    Kent|     M| 77000|\n",
      "|101|    Diana|  Prince|     F| 90000|\n",
      "|102|    Bruce|   Wayne|     M| 95000|\n",
      "|111|     Lois|    Lane|     F|145000|\n",
      "+---+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.orderBy(col('salary').asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67ece285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+------+------+\n",
      "| id|firstname|lastname|gender|salary|\n",
      "+---+---------+--------+------+------+\n",
      "|111|     Lois|    Lane|     F|145000|\n",
      "|106|    Clark|    Kent|     M| 77000|\n",
      "|102|    Bruce|   Wayne|     M| 95000|\n",
      "|101|    Diana|  Prince|     F| 90000|\n",
      "+---+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.orderBy(col('id').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0042c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------+--------------------+--------------------+--------------+\n",
      "|  id|firstname|  lastname|               email|              email2|    profession|\n",
      "+----+---------+----------+--------------------+--------------------+--------------+\n",
      "|1099|    Barbi|   Frendel|Barbi.Frendel@yop...|Barbi.Frendel@gma...|police officer|\n",
      "|1098| Cherilyn|   Frendel|Cherilyn.Frendel@...|Cherilyn.Frendel@...|        worker|\n",
      "|1097|     Maud|      Gert|Maud.Gert@yopmail...| Maud.Gert@gmail.com|        worker|\n",
      "|1096|  Teriann|  Holbrook|Teriann.Holbrook@...|Teriann.Holbrook@...|        doctor|\n",
      "|1095|    Deane|  Hartnett|Deane.Hartnett@yo...|Deane.Hartnett@gm...|        worker|\n",
      "|1094|   Blinni|     Haerr|Blinni.Haerr@yopm...|Blinni.Haerr@gmai...|        worker|\n",
      "|1093|     Mara|Wildermuth|Mara.Wildermuth@y...|Mara.Wildermuth@g...|   firefighter|\n",
      "|1092|   Marjie|  Eliathas|Marjie.Eliathas@y...|Marjie.Eliathas@g...|   firefighter|\n",
      "|1091|   Arabel|    Janene|Arabel.Janene@yop...|Arabel.Janene@gma...|police officer|\n",
      "|1090|    Wendi|    Cecile|Wendi.Cecile@yopm...|Wendi.Cecile@gmai...|        doctor|\n",
      "|1089|   Carlie|     Pauly|Carlie.Pauly@yopm...|Carlie.Pauly@gmai...|     developer|\n",
      "|1088|Charmaine|  Chauncey|Charmaine.Chaunce...|Charmaine.Chaunce...|     developer|\n",
      "|1087|    Misha|      Uird|Misha.Uird@yopmai...|Misha.Uird@gmail.com|     developer|\n",
      "|1086|   Florie|    Burkle|Florie.Burkle@yop...|Florie.Burkle@gma...|police officer|\n",
      "|1085|  Lorenza|   Bettine|Lorenza.Bettine@y...|Lorenza.Bettine@g...|        worker|\n",
      "|1084|   Lonnie|     Danby|Lonnie.Danby@yopm...|Lonnie.Danby@gmai...|   firefighter|\n",
      "|1083|   Briney|     Erich|Briney.Erich@yopm...|Briney.Erich@gmai...|   firefighter|\n",
      "|1082|   Annice|   Bethany|Annice.Bethany@yo...|Annice.Bethany@gm...|police officer|\n",
      "|1081|    Rayna|     Roche|Rayna.Roche@yopma...|Rayna.Roche@gmail...|   firefighter|\n",
      "|1080|  Aeriela|  Connelly|Aeriela.Connelly@...|Aeriela.Connelly@...|   firefighter|\n",
      "+----+---------+----------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.sort(fifa_df.id.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d610a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|    profession|count|\n",
      "+--------------+-----+\n",
      "|     developer|  215|\n",
      "|   firefighter|  193|\n",
      "|police officer|  188|\n",
      "|        worker|  214|\n",
      "|        doctor|  190|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.groupBy('profession').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee2ad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|max(id)|\n",
      "+-------+\n",
      "|   1099|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.select(max('id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f0bea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|min(id)|\n",
      "+-------+\n",
      "|    100|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.select(min('id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7336cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|avg(id)|\n",
      "+-------+\n",
      "|  599.5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.select(avg('id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cda6068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  stddev_samp(id)|\n",
      "+-----------------+\n",
      "|288.8194360957494|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.select(stddev('id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce91c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+--------------------+--------------------+--------------+\n",
      "| id|firstname|lastname|               email|              email2|    profession|\n",
      "+---+---------+--------+--------------------+--------------------+--------------+\n",
      "|100|    Lynde|  Orelee|Lynde.Orelee@yopm...|Lynde.Orelee@gmai...|   firefighter|\n",
      "|101|     Vere| Charity|Vere.Charity@yopm...|Vere.Charity@gmai...|police officer|\n",
      "|102|    Verla|Demitria|Verla.Demitria@yo...|Verla.Demitria@gm...|        worker|\n",
      "+---+---------+--------+--------------------+--------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fe218e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------------------+\n",
      "| id|firstname|(profession IN (firefighter))|\n",
      "+---+---------+-----------------------------+\n",
      "|100|    Lynde|                         true|\n",
      "|101|     Vere|                        false|\n",
      "|102|    Verla|                        false|\n",
      "|103|   Ebonee|                        false|\n",
      "|104|   Orsola|                        false|\n",
      "|105|   Ofilia|                        false|\n",
      "|106| Willetta|                        false|\n",
      "|107|Ekaterina|                        false|\n",
      "|108|  Gusella|                        false|\n",
      "|109|    Robbi|                        false|\n",
      "|110|   Melina|                        false|\n",
      "|111|   Leanna|                        false|\n",
      "|112|    Grier|                         true|\n",
      "|113|    Linzy|                        false|\n",
      "|114|     Fina|                        false|\n",
      "|115|  Brianna|                        false|\n",
      "|116|Morganica|                        false|\n",
      "|117|  Chloris|                        false|\n",
      "|118|  Aeriela|                        false|\n",
      "|119|   Dennie|                        false|\n",
      "+---+---------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df.select('id', 'firstname', fifa_df.profession.isin('firefighter')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f79189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|  id|firstname|\n",
      "+----+---------+\n",
      "| 100|    Lynde|\n",
      "| 128|    Lynea|\n",
      "| 146|   Lynnea|\n",
      "| 405|   Lynnea|\n",
      "| 486|    Lynea|\n",
      "| 603|   Lynnea|\n",
      "| 833|    Lyssa|\n",
      "| 843|    Lyssa|\n",
      "|1019|    Lyssa|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fifa_df[fifa_df.firstname.startswith('Ly')].select('id', 'firstname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f1cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|  id|firstname|\n",
      "+----+---------+\n",
      "| 603|   Lynnea|\n",
      "| 100|    Lynde|\n",
      "| 146|   Lynnea|\n",
      "| 486|    Lynea|\n",
      "|1019|    Lyssa|\n",
      "| 128|    Lynea|\n",
      "| 833|    Lyssa|\n",
      "| 405|   Lynnea|\n",
      "| 843|    Lyssa|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df = fifa_df[fifa_df.firstname.startswith('Ly')].select('id', 'firstname').dropDuplicates()\n",
    "demo_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a15310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---------+\n",
      "|  id|firstname|  New col|\n",
      "+----+---------+---------+\n",
      "| 603|   Lynnea|Added Col|\n",
      "| 100|    Lynde|Added Col|\n",
      "| 146|   Lynnea|Added Col|\n",
      "| 486|    Lynea|Added Col|\n",
      "|1019|    Lyssa|Added Col|\n",
      "| 128|    Lynea|Added Col|\n",
      "| 833|    Lyssa|Added Col|\n",
      "| 405|   Lynnea|Added Col|\n",
      "| 843|    Lyssa|Added Col|\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df2 = demo_df.withColumn('New col', lit(\"Added Col\"))\n",
    "demo_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18fbffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------+\n",
      "|  id|firstname|New column|\n",
      "+----+---------+----------+\n",
      "| 603|   Lynnea| Added Col|\n",
      "| 100|    Lynde| Added Col|\n",
      "| 146|   Lynnea| Added Col|\n",
      "| 486|    Lynea| Added Col|\n",
      "|1019|    Lyssa| Added Col|\n",
      "| 128|    Lynea| Added Col|\n",
      "| 833|    Lyssa| Added Col|\n",
      "| 405|   Lynnea| Added Col|\n",
      "| 843|    Lyssa| Added Col|\n",
      "+----+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df3 = demo_df2.withColumnRenamed('New col', 'New column')\n",
    "demo_df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa647acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|  id|firstname|\n",
      "+----+---------+\n",
      "| 603|   Lynnea|\n",
      "| 100|    Lynde|\n",
      "| 146|   Lynnea|\n",
      "| 486|    Lynea|\n",
      "|1019|    Lyssa|\n",
      "| 128|    Lynea|\n",
      "| 833|    Lyssa|\n",
      "| 405|   Lynnea|\n",
      "| 843|    Lyssa|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df3.drop('New column').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a5328c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('firstname', 'string'),\n",
       " ('lastname', 'string'),\n",
       " ('email', 'string'),\n",
       " ('email2', 'string'),\n",
       " ('profession', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "228014f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lynde'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_df.first()['firstname']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ca20d",
   "metadata": {},
   "source": [
    "# JOINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51095263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de4f99ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept = [(\"Finance\",10), \\\n",
    "    (\"Marketing\",20), \\\n",
    "    (\"Sales\",30), \\\n",
    "    (\"IT\",40) \\\n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c247a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc40b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"outer\").show()\n",
    "# OR\n",
    "# empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"full\").show()\n",
    "# OR\n",
    "# empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"fullouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb75c2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|     null|   null|\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"leftouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ac40ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|  Finance|     10|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|  Finance|     10|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|  Finance|     10|\n",
      "|  null|    null|           null|       null|       null|  null|  null|    Sales|     30|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|Marketing|     20|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|       IT|     40|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"rightouter\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34d32dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sparkbyexamples.com/pyspark/pyspark-join-explained-with-examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd5561",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7885f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+\n",
      "|firstname|lastname|gender|salary|\n",
      "+---------+--------+------+------+\n",
      "|    James|   Smith|     M|    30|\n",
      "|     Anna|    Rose|     F|    41|\n",
      "|   Robert|Williams|     M|    62|\n",
      "+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('James','Smith','M',30),\n",
    "  ('Anna','Rose','F',41),\n",
    "  ('Robert','Williams','M',62), \n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afd55a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+\n",
      "|           name|gender|new_salary|\n",
      "+---------------+------+----------+\n",
      "|    James,Smith|     M|        60|\n",
      "|      Anna,Rose|     F|        82|\n",
      "|Robert,Williams|     M|       124|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd2=df.rdd.map(lambda x: \n",
    "    (x[0]+\",\"+x[1],x[2],x[3]*2)\n",
    "    )  \n",
    "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af3a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
